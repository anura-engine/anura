//Additional functions for math.
{
	is_library: true,


#-------------------------- misc --------------------------#

	//x and y returns y if x is 0, use default(x,y) if 0 is a valid return.
	default: "def(decimal|null input, decimal|null fallback) -> decimal if(input is decimal, input, fallback asserting fallback is decimal)",
	



#-------------------------- number-range functions --------------------------#

	in_range: "def(decimal min, decimal var, decimal max) -> bool not var < min or var > max",

	/*
		Force the 2nd arg to be between the first and third arg, or at least as in-between as possible.
		
		The failure mode, 'center it', comes in to play when the minimum number is larger than the maximum.
		
		This is especially handy when dealing with variable-width GUIs, when you want something in the middle of a rectangular window with 100px of padding – or just in the center, if the 100px isn't available. While we could assert, it's less than helpful when your program crashes because someone's screen is too small.
	*/
	constrain: "overload( //The overload function allows you to provide multiple versions of the same function, but with different type signatures
		def(int min, int var, int max) -> int 
			if(min > max, (min+max)/2, if(min > var, min, if(max < var, max, var))),
		def(decimal min, decimal var, decimal max) -> decimal 
			if(min > max, (min+max)/2, if(min > var, min, if(max < var, max, var)))
		)",
	
	is_sorted: "def(list x) -> bool x = sort(x)", //Mostly good for testing range like if w<=x<=y. 
	
	
#-------------------------- rounding and decimal/int conversion functions --------------------------#
	/* 
		These also include some decimal versions of various integer-based builtins.  Decimals are Anura's name for "fixed-point storage of numbers with a decimal point in them (e.g. 1.3456)."
		
		Fixed-point numbers differ from floating point numbers in having far more stability when doing calculations (you don't get rounding errors), but pay for this by representing a far smaller set of possible values (the highest-possible number is much smaller).  They also have the advantage of being stable across different processor architectures, which floats are not.  For our needs, they're a considerably better tradeoff.
		
		
		floor, ceil, and round, have been built to enable one special requirement - they're suitable for symmetrical math that mirrors itself between -1 and 1. The following is true for floor, ceil, and round: f(x) = -f(-x).
	*/
	floor: "def(decimal num) -> int int(num)",

	ceil: "def(decimal num) -> int if(int(num) = num, int(num), int(num)+sign(num))",

	round: "def(decimal x) -> int round(x)", //Left this for consistency here after adding round() to the engine.


	/*
		Our built-in modulus function `mod(numerator, denominator)` and our built in remainder operator (the `%` operator) operate only on and only return integer values.
		The remainder operator returns the remainder left behind when a hypothetical `numerator/denominator` calculation would take place.

		The modulus function returns how a number would change when translated by a certain amount in a modulo-number-set; for example, what number a clock hand would be at if you moved it by `n` hours.  It is important that this work with decimal values, because many rudimentary graphics calculations (literally involving rotating objects and such, very analogous to a clock hand) need to move in fractional amounts.  We need to be able to ask "if a clock hand is pointing at 1 o'clock, and we move it backwards by 2.5 hours, what time is it pointing at now?".
		
		The decimal_mod function enables this.
		
		Historical Note:  We initially developed the ƒ(decimal, int) version of it, and later figured out how to do a ƒ(decimal, decimal) version (one which allowed a decimal in the denominator position as well).  We've left the version with the int type signature here in the interests of preserving something we trust to work correctly after a good deal of usage.
	*/
	decimal_mod: "overload(
					def(decimal val, int modulo) -> decimal mod(val, modulo) + val - floor(val),
					def(decimal val, decimal modulo) -> decimal val - floor(val/modulo) * modulo	
				)",

	/*
		This gives the fractional component of a decimal.  It will give you whatever digits are to the right of the decimal place. eg, ±2.413 → ±0.413.
	*/
	tenth: "def(decimal a) -> decimal a-int(a)", //Returns the number to the right of the decimal place. eg, ±2.4→±0.4.

	/*
		This rounds a decimal to the nearest decimal place:  i.e. round_to_decimal(1.33333, 10.0) gives 1.3
	*/
	round_to_decimal_precision: "def(decimal num, decimal magnitude) -> decimal round(num * magnitude) / magnitude",



#-------------------------- easing/interpolation --------------------------#
	interpolate: "overload(
	/* 
		Given a start, a percentage, and an end; return the appropriate in-between value. 
			Examples:
				- interpolate(5, 0.5, 0) would return 2.5.
				- interpolate(level.player, 0.75, [0,0]) would return a point three quarters of the way between the player and the point of origin.
		Given a list of things and a percentage, return the thing (a point or decimal) that is percent of the way along the list. All points are weighted evenly. Points can be anything that lib.standardize.toPoint accepts as input.
			Use: interpolate(list_of_stops, percent)
			For example, between 0.0 and 1.0 for [1,3,1], we'd have the following values returned: 
				[1.0, 1.4, 1.8, 2.2, 2.6, 3.0, 2.6, 2.2, 1.8, 1.4, 1.0]
	*/
		//3 ARITY
		def(decimal begin, decimal percentage, decimal end) -> decimal 
			tween(end, begin, percentage),
		
		def([decimal] begin, decimal percentage, [decimal] end) -> [decimal] 
			[decimal] <- tween(end, begin, percentage) //The base case, where we just tween between the two.
				asserting size(begin) = size(end) 
						  | {begin:begin, end:end},
					  
		(def([decimal] begin, decimal percentage, object|map end) -> map 
			({mid_x:x_, mid_y:y_, 0:x_, 1:y_} where    //Extract and tween.
				x_ = tween(decimal <- end.mid_x, begin[0], percentage), 
				y_ = tween(decimal <- end.mid_y, begin[1], percentage)) 
				asserting end.mid_x != null, 
						  end.mid_y != null, 
						  size(begin)=2 
						  | {begin:begin, end:end}),
					  
		(def(object|map begin, decimal percentage, [decimal] end) -> map 
			({mid_x:x_, mid_y:y_, 0:x_, 1:y_} where 
				x_ = tween(end[0], decimal <- begin.mid_x, percentage), 
				y_ = tween(end[1], decimal <- begin.mid_y, percentage)) 
				asserting begin.mid_x != null, 
						  begin.mid_y != null, 
						  size(end)=2 
						  | {begin:begin, end:end}),
					  
		(def(object|map begin, decimal percentage, object|map end) -> map {
			mid_x:tween(decimal <- end.mid_x, decimal <- begin.mid_x, percentage), 
			mid_y:tween(decimal <- end.mid_y, decimal <- begin.mid_y, percentage)
			} asserting begin.mid_x != null, 
						end.mid_x != null, 
						begin.mid_y != null, 
						end.mid_y != null),
					
		//2 ARITY
		def({decimal -> decimal} targets, decimal step) -> decimal 
			//We'll take the list of points as verticies connected by edges (think fence-posts). Each edge has two verticies, and we'll tween between those.
			(tween(targets[second_key], targets[first_key], (step-first_key)/total_range) where 
				total_range = second_key - first_key where first_key=decimal(min(keys(targets))), 
				second_key = decimal(max(keys(targets))) 
			) asserting size(targets) = 2,
		
		(def([object|map|[decimal]]|[decimal] targets, decimal step) -> decimal|[decimal]|map 
			interpolate(
				object|map|[decimal]|decimal <- targets[chunkIndex], 
				chunkPercent, 
				object|map|[decimal]|decimal <- if(size(targets)!=chunkIndex+1, 
												   targets[chunkIndex+1], 
												   targets[chunkIndex])
			) where chunkIndex = int(expandedPercent), 
					chunkPercent = tenth(expandedPercent)
					where expandedPercent = step*(size(targets)-1)) 
				
	) where tween = overload(
	
		def(decimal list_one, decimal list_two, decimal percent_raw) -> decimal 
			//Percent_raw may be ever so slightly above 1 or below 0, depending on some less-than-percise math elsewhere. For example, the camera controller will ask for percent 1.0005 on its last frame.
			(list_one*(percent) + list_two*(1.0-percent)) where percent = constrain(0, percent_raw, 1),
	
		def([decimal] list_one, [decimal] list_two, decimal percent_raw) -> list 
			//Same as before, but now combine each element of both lists weighted by percent.
			zip(list_one, list_two, 
				a*percent + b*(1.0-percent)
			) where percent = lib.math.constrain(0, percent_raw, 1)
	)",


	//This is a really basic smooth-step function, like the above but faster and without the constraints interpolate has.
	//Takes three decimals; start, stop, and percent of the way between the two.
	smooth_step: "def(decimal a, decimal b, decimal percent) -> decimal
		b*percent + a*(1-percent)",




	//Easing functions. Takes a percent (a decimal between 0 and 1) and weights it.
	//Easing functions from easings.net. t: current time, b: beginning value, c: change In value, e: total time
	//Example: lib.math.interpolate([2,3], lib.math.ease_in_cubic(2.0/3.0), [5,6]) ~> [2.888, 3.888]
	//Warning: These functions have only been tested for varying t. Varying b, c, or e is untested.
	linear: "def(decimal t) -> decimal t",
	
	ease_in_quad: "def(decimal t) -> decimal
		t^2",
		
	ease_out_quad: "def(decimal t) -> decimal
		1 - (t-1)^2",
		
	ease_in_out_quad: "def(decimal t) -> decimal
		let t = t * 2;
		if(t < 1,
			t^2 / 2,
			-((t-2)^2 - 2) / 2
		)",
		  
		  
	ease_in_cubic: "def(decimal t) -> decimal
		t^3",
	ease_out_cubic: "def(decimal t) -> decimal
		1 + (t-1)^3",
	ease_in_out_cubic: "def(decimal t) -> decimal
		let t = t*2;
		if(t < 1,
			t^3 / 2,
			((t-2)^3 + 2) / 2
		)",
		  

	ease_in_quart: "def(decimal t) -> decimal
		t^4",

	ease_out_quart: "def(decimal t) -> decimal
		-((t-1)^4 - 1)",

	ease_in_out_quart: "def(decimal t) -> decimal
		let t = t*2;
		if(t < 1,
			t^4 / 2,
			-((t-2)^4 - 2) / 2
		)",
		  

	ease_in_quint: "def(decimal t) -> decimal
		t^5",

	ease_out_quint: "def(decimal t) -> decimal
		1 + (t-1)^5",

	ease_in_out_quint: "def(decimal t) -> decimal
		let t = t*2;
		if(t < 1,
			t^5 / 2,
			((t-2)^5 + 2) / 2
		)",
		

	ease_in_sine: "def(decimal t) -> decimal
		-cos(deg(t * pi/2)) + 1 
			where deg = lib.standardize.radians_to_degrees",

	ease_out_sine: "def(decimal t) -> decimal
		sin(deg(t * pi/2)) 
			where deg = lib.standardize.radians_to_degrees",

	ease_in_out_sine: "def(decimal t) -> decimal
		-(cos(deg(t * pi)) - 1) / 2 
			where deg = lib.standardize.radians_to_degrees",


	ease_in_expo: "def(decimal t) -> decimal
		if(t=0, 0.0, 2^(10 * (t - 1)))",	

	ease_out_expo: "def(decimal t) -> decimal
		if(t=1, 1.0, -2^(-10 * t) + 1)",

	ease_in_out_expo: "def(decimal t) -> decimal
		let t = t*2;
		switch(true, 
			t=0, 0.0, 
			t=2, 1.0, 
			t<1, 2^(10 * (t - 1)) / 2,
			     (-2^(-10 * (t - 1)) + 2) /2
		)",
		

	ease_in_circ: "def(decimal t) -> decimal
		-sqrt(1 - t^2) + 1",

	ease_out_circ: "def(decimal t) -> decimal
		sqrt(1 - (t-1)^2)",

	ease_in_out_circ: "def(decimal t) -> decimal
		let t = t*2;
		if(t < 1, 
			-(sqrt(1 - t^2) - 1) / 2,
			(sqrt(1 - (t-2)^2) + 1) / 2
		)",
		

	ease_in_elastic: "def(decimal t) -> decimal
		let s = 0.3/(2*pi) * rad(asin(1)) 
			where rad = lib.standardize.degrees_to_radians;
		
		if(t=0, 0.0, 
			-1.0 * 2^(10*(t-1)) * sin(deg( ((t-1)-s) * (2*pi)/0.3 ))
				where deg = lib.standardize.radians_to_degrees
		)",

	ease_out_elastic: "def(decimal t) -> decimal
		let s = 0.3/(2*pi) * rad(asin(1))
			where rad = lib.standardize.degrees_to_radians;
		
		if(t=1, 1.0,
			2^(-10*t) * sin(deg( (t-s) * (2*pi)/0.3 )) + 1.0
				where deg = lib.standardize.radians_to_degrees
		)",

	ease_in_out_elastic: "def(decimal t) -> decimal
		let s = 0.45/(2*pi) * rad(asin(1)) 
			where rad = lib.standardize.degrees_to_radians;
		
		let t = t*2;
		switch(true, 
			t=0, 0.0, 
			t=2, 1.0,
			t<1, -2^(10*(t-1)) * sin(deg( ((t-1)*1-s) * (2*pi)/0.45 )) / 2,
				 2^(-10*(t-1)) * sin(deg( ((t-1)*1-s) * (2*pi)/0.45 )) / 2 + 1.0
		) where deg = lib.standardize.radians_to_degrees",
	

	ease_in_back: "def(decimal t) -> decimal 
		let s = 1.70158;
		t^2*((s+1)*t - s)",

	ease_out_back: "def(decimal t) -> decimal
		let s = 1.70158;
		let t = t-1; 
		t^2*((s+1)*t + s) + 1",

	ease_in_out_back: "def(decimal t) -> decimal
		let s = 2.59490;
		if(t < 0.5,
			let t = t*2;   t^2*((s+1)*t - s) / 2,
			let t = t*2-2; t^2*((s+1)*t + s) / 2 + 1
		)",


	ease_in_bounce: "def(decimal t) -> decimal
		1 - ease_out_bounce(1-t)",

	ease_out_bounce: "def(decimal t) -> decimal
		switch(true, 
			t < 1.0/2.75,  7.5625* t            ^2            ,
			t < 2.0/2.75, (7.5625*(t-1.500/2.75)^2 + 0.750000),
			t < 2.5/2.75, (7.5625*(t-2.250/2.75)^2 + 0.937500),
			              (7.5625*(t-2.625/2.75)^2 + 0.984375)
		)",

	ease_in_out_bounce: "def(decimal t) -> decimal
		if(t < 0.5, 
			      ease_in_bounce (t*2  )*0.5,
			0.5 + ease_out_bounce(t*2-1)*0.5
		)",
	
	


#-------------------------- line/rectangle geometry --------------------------#

	length: "overload(
		def(decimal a, decimal b, decimal u, decimal v) -> decimal hypot(a-u, b-v), //c,d? d is for dice, 2d20, and can't be used.
		def([decimal] a, [decimal] b) -> decimal length(a[0], a[1], b[0], b[1]),
		def(custom_obj a, [decimal] b) -> decimal length(a.midpoint_x, a.midpoint_y, b[0], b[1]),
		def([decimal] a, custom_obj b) -> decimal length(a[0], a[1], b.midpoint_x, b.midpoint_y),
		def(custom_obj a, custom_obj b) -> decimal length(a.midpoint_x, a.midpoint_y, b.midpoint_x, b.midpoint_y),
	
		def(decimal u, decimal v) -> decimal length(0,0,u,v),
		def([decimal] b) -> decimal length(0,0, b[0],b[1])
	)",

	rect_intersect: "overload( 
		//Takes two RectXY Rects, or two RectWH Rects and a reference to (for example) lib.standardize.to_rect_xy as the third arg.
		def(Rect a, Rect b) -> bool not
			a[0] > b[2] or a[2] < b[0] or 
			a[1] > b[3] or a[3] < b[1],
		def(Rect a, Rect b, function(Rect)->Rect standardize) -> bool
			rect_intersect(standardize(a), standardize(b))
	)",


#-------------------------- circular/trigonometric geometry --------------------------#
	/*
		Useful for normalizing when adding the degrees of a circle together. Always returns a positive.
		Example use: We want a value between 0° and 360°, so we can divide by 360.0° and tell how much of a percent around a circle we are. Say, for a dial control.
		Our equation is 45+90+90+180 degrees. loop returns 45 degrees, so we know we're 12.5% the way around our circle.
	*/
	loop: "overload(
		def(decimal a) -> decimal loop(a, 360),
		def(decimal a, decimal lim) -> decimal decimal_mod((lim + decimal_mod(a,lim)),lim)  //
	)",
	
	
	/*
		Calculate the angle between a point of some sort and another point. The four-arg version, accepting x1,y1,x2,y2, is to keep parity with the built-in angle function.
		This is a convenience function so you don't have to manually separate out the components of your points. It just uses the engine angle function.
	*/
	angle: "overload( //this returns an int because of loop
		def(decimal x1, decimal y1, decimal x2, decimal y2) -> decimal loop(angle(x1, y1, x2, y2)), //Normalize the return value to between 0 and 360, because that is the most expected.
		def([decimal] p1, [decimal] p2) -> decimal lib.math.angle(p1[0], p1[1], p2[0], p2[1]),
		def(object|map p1, object|map p2) -> decimal lib.math.angle(
			decimal <- default(decimal|null <- p1.mid_x, decimal|null <- p1.x), 
			decimal <- default(decimal|null <- p1.mid_y, decimal|null <- p1.y), 
			decimal <- default(decimal|null <- p2.mid_x, decimal|null <- p2.x), 
			decimal <- default(decimal|null <- p2.mid_y, decimal|null <- p2.y)),
		def(object|map p1, [decimal] p2) -> decimal lib.math.angle(
			decimal <- default(decimal|null <- p1.mid_x, decimal|null <- p1.x), 
			decimal <- default(decimal|null <- p1.mid_y, decimal|null <- p1.y), p2[0], p2[1]),
		def([decimal] p1, object|map p2) -> decimal lib.math.angle(p1[0], p1[1], 
			decimal <- default(decimal|null <- p2.mid_x, decimal|null <- p2.x), 
			decimal <- default(decimal|null <- p2.mid_y, decimal|null <- p2.y)),
		
		def(decimal a, decimal b) -> decimal lib.math.angle(0,0,a,b),
		def([decimal] p1) -> decimal lib.math.angle(0,0,p1[0],p1[1])
	)",


	//This function could use some love. It was just copy/pasted out of an ancient controller for curved ropes.
	bezier_curve: "def([Point2d] points, decimal percent_raw) -> Point2d
		if(size(points) < 2,
			points[0], //Just return the point, no work to be done.
			if(size(points)=2, 
				[(decimal <- points[0][0]*(1-percent)) + (decimal <- points[1][0]*percent), (decimal <- points[0][1]*(1-percent)) + (decimal <- points[1][1]*percent)], 
				bezier_curve([Point2d] <- map(range(size(points)-1), 'ind', bezier_curve([Point2d] <- points[ind:ind+2], percent)), percent)
		)) where percent = decimal(percent_raw) 
		   asserting size(points)",


	rotate: "overload(
		def(decimal x, decimal y, decimal rotation, Point2d point) -> Point2d
			Point2d <- rotate_rect(int(x), int(y), rotation, map(point, int(value))),
		def(Point2d xy, decimal rotation, Point2d point) -> Point2d
			rotate(xy[0], xy[1], rotation, point),
		def(decimal x, decimal y, decimal rotation, [Point2d] points) -> [Point2d]
			map(points, rotate(x, y, rotation, value)),
		def(Point2d xy, decimal rotation, [Point2d] points) -> [Point2d]
			map(points, rotate(xy[0], xy[1], rotation, value)),
		
		def(decimal rotation, Point2d point) -> Point2d
			rotate(0, 0, rotation, point),
		def(decimal rotation, [Point2d] points) -> [Point2d]
			map(points, rotate(0, 0, rotation, value)),
	)",

		//This is designed to be used - at least its initial use, for spawning random objects in a certain arc; 
	random_radial_pos:	"def({min_angle: decimal, max_angle: decimal, angle_delta_scale: decimal, origin: {x: decimal, y: decimal}, min_length: decimal, max_length: decimal} p) -> {x:decimal, y:decimal}
				{x: p.origin.x + offset.x, y: p.origin.y + offset.y}

			where offset = { x: decimal, y: decimal } :: { x: length * cos(angle), y: length * sin(angle) }
			where length = p.min_length + 1d(p.max_length - p.min_length)
			where angle = p.min_angle + (p.angle_delta_scale * 1d(p.max_angle - p.min_angle))
			
			asserting (p.angle_delta_scale >= 0.0 and p.angle_delta_scale <= 1.0)",
	
		//uses the prior function - most of these params are passthroughs.  This generates a set of random values, all trying to be evenly spread out in separate "cells".
		//if you just want a totally random "shotgun spread" (with clustering), then you just do a simple map over the prior function without any of this special logic.
	randomized_even_spread_radial_distribution: "def({count: int, min_angle: decimal, max_angle: decimal, angle_delta_scale: decimal, origin: {x: decimal, y: decimal}, min_length: decimal, max_length: decimal} p) -> [{x:decimal, y:decimal}]
			map(range(p.count), random_radial_pos({min_angle: current_min_angle, max_angle: current_max_angle, angle_delta_scale: p.angle_delta_scale, origin: {x: p.origin.x, y: p.origin.y}, min_length: p.min_length, max_length: p.max_length})
						where current_min_angle = p.min_angle + (interval_length * (value - 1))
						where current_max_angle = p.min_angle + (interval_length * value)
						where interval_length = (p.max_angle - p.min_angle) / decimal(p.count)
			)",

#-------------------------- line-of-sight geometry --------------------------#

	/*
	Answers the question, "Can object A see object B?"

	Takes: 1) A level. 2) The custom_obj object A. 3) The hittable or custom_obj object B.
	Returns an object with 
		clear: bool (ie, clear line of sight) = true if can see directly
		saw: First hittable object (or object B) or null if no object seen

	Remarks: Perhaps this should go in a different library? math.cfg shouldn't really hold level-based geometry functions like this.
	*/
	clear_line_of_sight_between: "overload(
		def(level level, custom_obj obj_a, custom_obj obj_b) -> {clear: bool, saw: null | custom_obj}
			{clear: bool, saw: null | custom_obj} <- _cs_step_to_collision(level, _cs_line_of_sight(obj_a, obj_b), obj_a, obj_b),
		def(level level, custom_obj obj_a, custom_obj obj_b) -> {clear: bool, saw: null | custom_obj}
			_cs_step_to_collision(level, _cs_line_of_sight(obj_a, obj_b), obj_a, obj_b)
		)",
	_cs_step_to_collision: "def(level level, [Point] steps, custom_obj obj_a, custom_obj obj_b, int iteration=0) -> {clear: bool, saw: null | custom_obj} //This doesn't work, returning merely a bunch of strings - a list of valid functions?
		base iteration = size(steps): 
			{clear: true, saw: obj_b} //No collisions.
		base solid(level, int(steps[iteration][0]), int(steps[iteration][1]), 2, 2): //Append 'true' to see where is being tested. 
			{clear: false, saw: null} //Level collision.
		base find(filter(level.active_chars, value is custom_obj and value not in [obj_a, obj_b]), 'char', 
				char.solid_rect.x < steps[iteration][0] and steps[iteration][0] < char.solid_rect.x2 and
				char.solid_rect.y < steps[iteration][1] and steps[iteration][1] < char.solid_rect.y2) :
			{clear: false, saw:
			find(filter(level.active_chars, value is custom_obj and value not in [obj_a, obj_b]), 'char', 
				char.solid_rect.x < steps[iteration][0] and steps[iteration][0] < char.solid_rect.x2 and
				char.solid_rect.y < steps[iteration][1] and steps[iteration][1] < char.solid_rect.y2) }
		recursive: _cs_step_to_collision(level, steps, obj_a, obj_b, iteration+1)",
	//Return a list of points on the line of sight between the two objects.
	_cs_line_of_sight: "def(custom_obj obj_a, custom_obj obj_b) -> [Point] 
		map(range(steps_to_fire+1), 'step', [
			(fot[0]*(percent) + gs[0]*(1.0-percent)),
			(fot[1]*(percent) + gs[1]*(1.0-percent))
		] where percent = step/1.0/steps_to_fire
		) where steps_to_fire = _cs_steps_to_fire(obj_a, obj_b)
		where gs = obj_a.mid_xy,
			  fot = obj_b.mid_xy",
	  
	_cs_steps_to_fire: "def(custom_obj obj_a, custom_obj obj_b) -> int round(length(obj_a, obj_b)/10)",
#-------------------------- Functions inspired by or directly translated from iquilezles.org. I wish I understood the math. --------------------------#
	// See http://iquilezles.org/www/articles/functions/functions.htm
	/*
	Takes decimal value, decimal threshhold, decimal replacement value.
	Say you don't want to change a value unless it's too small and screws some of
	your computations up. Then, rather than doing a sharp conditional branch, you
	can blend your value with your threshold, and do it smoothly (say, with a cubic
	polynomial). Set m to be your threshold (anything above m stays unchanged), and 
	n the value things will take when your value is zero.
	*/
	almost_identity: "def(decimal x, decimal m, decimal n) -> decimal
		if(x >= m, 
			decimal(x), 
			((a*t + b)*t^2 + n where
				a = 2.0*n - m,
				b = 2.0*m - 3.0*n,
				t = x/1.0/m)
		)
	",
	//For symmetry, we of course also need...
	identity: "def(any x) -> any x",
	/*
	Great for triggering behaviours or making envelopes for music or animation, and
	for anything that grows fast and then slowly decays. Use k to control the
	streching o the function. Btw, it's maximun, which is 1.0, happens at exactly x
	= 1/k.
	*/
	impulse: "def(decimal k, decimal x) -> decimal
		h * exp(1.0-h) where h = k*x",
	/*
	Takes pulse center-mark, pulse duration, and input centered around the center-mark. Returns a value between 1 and 0.
	Of course you found yourself doing smoothstep(c-w,c,x)-smoothstep(c,c+w,x) very
	often, probably cause you were trying to isolate some features. Then this
	cubicPulse() is your friend. Also, why not, you can use it as a cheap
	replacement for a gaussian.
	*/
	cubic_pulse: "def(decimal c, decimal w, decimal x_a) -> decimal
		if(x_b > w, 
			0.0, 
			1.0 - x_c^2 * (3 - 2*x_c) 
				where x_c = x_b/1.0/w
		) where x_b = decimal(abs(x_a - c))
	",
	/*
	Takes a range around 0..1 and a parabola curve factor of around 1. Outputs 0 when range is 0 or 1, and 1 when range is 0.5.
	A natural attenuation is an exponential of a linearly decaying quantity: yellow*
	curve, exp(-x). A gaussian, is an exponential of a quadratically decaying
	quantity: light green curve, exp(-x²). You can go on increasing powers, and get
	a sharper and sharper smoothstep(), until you get a step() in the limit.
	*Note: See the website for the graph this is referring to.
	*/
	exponential_step: "def(decimal x, decimal k, decimal n) -> decimal exp(-k*x^n)",
	/*
	A nice choice to remap the 0..1 interval into 0..1, such that the corners are
	remaped to 0 and the center to 1. In other words, parabola(0) = parabola(1) = 0,
	and parabola(1/2) = 1.
	*/
	parabola: "def(decimal x, decimal k) -> decimal (4.0*x*(1.0-x))^k",
//And, some constants...
e: 2.718281,
pi: 3.141592,
test: [
	{
		assert: "map(range(11), lib.math.interpolate([1,3,1], value/10.0)) 
			= [1.0, 1.4, 1.8, 2.2, 2.6, 3.0, 2.6, 2.2, 1.8, 1.4, 1.0]"
	},{
		assert: "lib.math.interpolate({mid_x:100, mid_y:50}, 0.40, {mid_x:0, mid_y:-10})
			= {mid_x:60, mid_y:26}"
	},
	
	{
		assert: "lib.math.smooth_step(5, 10, -2) = -5"
	},{
		assert: "lib.math.smooth_step(5, 10, -1) = 0"
	},{
		assert: "lib.math.smooth_step(5, 10, -0.5) = 2.5"
	},{
		assert: "lib.math.smooth_step(5, 10, 0) = 5"
	},{
		assert: "lib.math.smooth_step(5, 10, 0.5) = 7.5"
	},{
		assert: "lib.math.smooth_step(5, 10, 2) = 15"
	},
	{
		assert: "lib.math.loop(360) = 0"
	},{
		assert: "lib.math.loop(360+45) = 45"
	},{
		assert: "lib.math.loop(-360+45) = 45"
	},{
		assert: "lib.math.loop(720+90) = 90"
	},{
		assert: "lib.math.loop(-720+90) = 90"
	},
	
	{
		assert: "lib.math.round(-5.4) = -5"
	},{
		assert: "lib.math.round(-5.5) = -6"
	},{
		assert: "lib.math.round(-5.6) = -6"
	},{
		assert: "lib.math.round( 5.4) =  5"
	},{
		assert: "lib.math.round( 5.5) =  6"
	},{
		assert: "lib.math.round( 5.6) =  6"
	},
	
	{
		assert: "lib.math.floor( 4.9) =  4"
	},{
		assert: "lib.math.floor( 4.2) =  4"
	},{
		assert: "lib.math.floor(-4.9) = -4"
	},{
		assert: "lib.math.floor(-4.2) = -4"
	},
	
	{
		assert: "lib.math.ceil( 4.9) =  5"
	},{
		assert: "lib.math.ceil( 4.2) =  5"
	},{
		assert: "lib.math.ceil(-4.9) = -5"
	},{
		assert: "lib.math.ceil(-4.2) = -5"
	},
	
	{
		assert: "abs(lib.math.length(-20,30, 80,90) - 116.619037) < 0.0001"
	}, {
		assert: "lib.math.length(-20,30, 80,90) = lib.math.length([-20,30], [80,90])", //TODO: Add an object to this library so we can make one to test this function with.
	},
	{
		//Since angle uses floating-point numbers under the hood, we'll not get back an exact answer.
		//Instead, we'll check that the difference between the expected result and the desired result is within a reasonable margin.
		assert: "abs(angle(1,2,3,4) - 45) < 0.0001"
	},{
		assert: "lib.math.angle({x:10, y:5}, [0,5]) - 180 < 0.0001"
	},
	
	{
		assert: "lib.math.rect_intersect([1056, 128, 1172, 244],[1119, 201, 1119, 201])"
	},
	
	{
		assert: "lib.math.almost_identity(0, 2, 1) = 1"
	},{
		assert: "lib.math.almost_identity(1, 2, 1) = 1.25"
	},{
		assert: "lib.math.almost_identity(2, 2, 1) = 2"
	},
	
	{
		assert: "lib.math.impulse(0.25, 4) = 1"
	},{
		assert: "lib.math.impulse(0.20, 5) = 1"
	},{
		assert: "lib.math.impulse(0.25, 0) = 0"
	},{
		assert: "lib.math.is_sorted([-0.001, lib.math.impulse(0.50, 4) - 0.735758, 0.001])"
	},
	
	{
		assert: "lib.math.cubic_pulse(1,1,0) = 0"
	},{
		assert: "lib.math.cubic_pulse(1,1,1) = 1"
	},{
		assert: "lib.math.cubic_pulse(1,1,2) = 0"
	},
	
	{
		//For each function which starts with 'ease_', in this file, check that it's output matches a precalculated 'known good' output. Three precalculated values were adjusted for rounding errors by ±0.0001.
		assert: "map(filter(keys(lib.math), value[:5] = 'ease_'), 'easing_function',
			true asserting precalculated_results[easing_function] = map(
				range(0,11,1),
				lib.math.round_to_decimal_precision(
					lib.math[easing_function](value/10.0),
					10000.0
				)
			) | easing_function
		)
			where precalculated_results = {
				ease_in_quad:        [ 0.0000,  0.0100,  0.0400,  0.0900,  0.1600,  0.2500,  0.3600,  0.4900,  0.6400,  0.8100,  1.0000, ],
				ease_out_quad:       [ 0.0000,  0.1900,  0.3600,  0.5100,  0.6400,  0.7500,  0.8400,  0.9100,  0.9600,  0.9900,  1.0000, ],
				ease_in_out_quad:    [ 0.0000,  0.0200,  0.0800,  0.1800,  0.3200,  0.5000,  0.6800,  0.8200,  0.9200,  0.9800,  1.0000, ],
				ease_in_cubic:       [ 0.0000,  0.0010,  0.0080,  0.0270,  0.0640,  0.1250,  0.2160,  0.3430,  0.5120,  0.7290,  1.0000, ],
				ease_out_cubic:      [ 0.0000,  0.2710,  0.4880,  0.6570,  0.7840,  0.8750,  0.9360,  0.9730,  0.9920,  0.9990,  1.0000, ],
				ease_in_out_cubic:   [ 0.0000,  0.0040,  0.0320,  0.1080,  0.2560,  0.5000,  0.7440,  0.8920,  0.9680,  0.9960,  1.0000, ],
				ease_in_quart:       [ 0.0000,  0.0001,  0.0016,  0.0081,  0.0256,  0.0625,  0.1296,  0.2401,  0.4096,  0.6561,  1.0000, ],
				ease_out_quart:      [ 0.0000,  0.3439,  0.5904,  0.7599,  0.8704,  0.9375,  0.9744,  0.9919,  0.9984,  0.9999,  1.0000, ],
				ease_in_out_quart:   [ 0.0000,  0.0008,  0.0128,  0.0648,  0.2048,  0.5000,  0.7952,  0.9352,  0.9872,  0.9992,  1.0000, ],
				ease_in_quint:       [ 0.0000,  0.0000,  0.0003,  0.0024,  0.0102,  0.0313,  0.0778,  0.1681,  0.3277,  0.5905,  1.0000, ],
				ease_out_quint:      [ 0.0000,  0.4095,  0.6723,  0.8319,  0.9222,  0.9688,  0.9898,  0.9976,  0.9997,  1.0000,  1.0000, ],
				ease_in_out_quint:   [ 0.0000,  0.0002,  0.0051,  0.0389,  0.1638,  0.5000,  0.8362,  0.9611,  0.9949,  0.9998,  1.0000, ],
				ease_in_sine:        [ 0.0000,  0.0123,  0.0489,  0.1090,  0.1910,  0.2929,  0.4122,  0.5460,  0.6910,  0.8436,  1.0000, ],
				ease_out_sine:       [ 0.0000,  0.1564,  0.3090,  0.4540,  0.5878,  0.7071,  0.8090,  0.8910,  0.9511,  0.9877,  1.0000, ],
				ease_in_out_sine:    [ 0.0000,  0.0245,  0.0955,  0.2061,  0.3455,  0.5000,  0.6545,  0.7939,  0.9045,  0.9755,  1.0000, ],
				ease_in_expo:        [ 0.0000,  0.0020,  0.0039,  0.0078,  0.0156,  0.0313,  0.0625,  0.1250,  0.2500,  0.5000,  1.0000, ],
				ease_out_expo:       [ 0.0000,  0.5000,  0.7500,  0.8750,  0.9375,  0.9688,  0.9844,  0.9922,  0.9961,  0.9980,  1.0000, ],
				ease_in_out_expo:    [ 0.0000,  0.0020,  0.0078,  0.0313,  0.1250,  0.5000,  0.8750,  0.9688,  0.9922,  0.9980,  1.0000, ],
				ease_in_circ:        [ 0.0000,  0.0050,  0.0202,  0.0461,  0.0835,  0.1340,  0.2000,  0.2859,  0.4000,  0.5641,  1.0000, ],
				ease_out_circ:       [ 0.0000,  0.4359,  0.6000,  0.7141,  0.8000,  0.8660,  0.9165,  0.9539,  0.9798,  0.9950,  1.0000, ],
				ease_in_out_circ:    [ 0.0000,  0.0101,  0.0417,  0.1000,  0.2000,  0.5000,  0.8000,  0.9000,  0.9583,  0.9899,  1.0000, ],
				ease_in_elastic:     [ 0.0000,  0.0020, -0.0020, -0.0039,  0.0156, -0.0156, -0.0312,  0.1250, -0.1250, -0.2500,  1.0000, ],
				ease_out_elastic:    [ 0.0000,  1.2500,  1.1250,  0.8750,  1.0313,  1.0156,  0.9844,  1.0039,  1.0020,  0.9980,  1.0000, ],
				ease_in_out_elastic: [ 0.0000,  0.0003, -0.0039,  0.0239, -0.1175,  0.5000,  1.1175,  0.9761,  1.0039,  0.9997,  1.0000, ],
				ease_in_back:        [ 0.0000, -0.0143, -0.0465, -0.0802, -0.0994, -0.0877, -0.0290,  0.0929,  0.2942,  0.5912,  1.0000, ],
				ease_out_back:       [ 0.0000,  0.4088,  0.7058,  0.9071,  1.0290,  1.0877,  1.0994,  1.0802,  1.0465,  1.0143,  1.0000, ],
				ease_in_out_back:    [ 0.0000, -0.0375, -0.0926, -0.0788,  0.0899,  0.5000,  0.9101,  1.0788,  1.0926,  1.0375,  1.0000, ],
				ease_in_bounce:      [ 0.0000,  0.0119,  0.0600,  0.0694,  0.2275,  0.2344,  0.0900,  0.3194,  0.6975,  0.9244,  1.0000, ],
				ease_out_bounce:     [ 0.0000,  0.0756,  0.3025,  0.6806,  0.9100,  0.7656,  0.7725,  0.9306,  0.9400,  0.9881,  1.0000, ],
				ease_in_out_bounce:  [ 0.0000,  0.0300,  0.1138,  0.0450,  0.3488,  0.5000,  0.6513,  0.9550,  0.8862,  0.9700,  1.0000, ],
			}"
	}
],
}
